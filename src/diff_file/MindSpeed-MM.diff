diff --git a/pretrain_internvl.py b/pretrain_internvl.py
index 9efc16c..07ff32d 100644
--- a/pretrain_internvl.py
+++ b/pretrain_internvl.py
@@ -19,7 +19,10 @@ from mindspeed_mm.models.internvl_model import InternVLModel
 from mindspeed_mm.utils.transformer_model_config import get_model_config
 from mindspeed_mm.utils.utils import EncoderBalanceComm
 from mindspeed_mm.patchs import dummy_optimizer_patch
-
+from mindspeed.megatron_adaptor import get_mindspeed_args
+mindspeed_args = get_mindspeed_args()
+if hasattr(mindspeed_args, "ai_framework") and mindspeed_args.ai_framework == "mindspore" and mindspeed_args.optimization_level >= 0:
+    import mindspeed_mm.mindspore.mindspore_adaptor
 
 def model_provider(pre_process=True, post_process=True):
     """Builds the model."""


diff --git a/pretrain_deepseekvl.py b/pretrain_deepseekvl.py
index 74250cd..f9d11ff 100644
--- a/pretrain_deepseekvl.py
+++ b/pretrain_deepseekvl.py
@@ -18,6 +18,10 @@ from mindspeed_mm.models.deepseekvl_model import VLMModel
 from mindspeed_mm.training import pretrain
 from mindspeed_mm.utils.transformer_model_config import get_model_config
 from mindspeed_mm.patchs import dummy_optimizer_patch
+from mindspeed.megatron_adaptor import get_mindspeed_args
+mindspeed_args = get_mindspeed_args()
+if hasattr(mindspeed_args, "ai_framework") and mindspeed_args.ai_framework == "mindspore" and mindspeed_args.optimization_level >= 0:
+    import mindspeed_mm.mindspore.mindspore_adaptor
 
 
 def model_provider(pre_process=True, post_process=True):
diff --git a/pretrain_llava.py b/pretrain_llava.py
index bd11cf2..fa5ffd9 100644
--- a/pretrain_llava.py
+++ b/pretrain_llava.py
@@ -20,6 +20,10 @@ from mindspeed_mm.configs.config import MMConfig
 from mindspeed_mm.data import build_mm_dataloader, build_mm_dataset
 from mindspeed_mm.utils.transformer_model_config import get_model_config
 from mindspeed_mm.models.common.module_spec.llava_layer_spec import get_layer_spec, get_mlp_module_spec
+from mindspeed.megatron_adaptor import get_mindspeed_args
+mindspeed_args = get_mindspeed_args()
+if hasattr(mindspeed_args, "ai_framework") and mindspeed_args.ai_framework == "mindspore" and mindspeed_args.optimization_level >= 0:
+    import mindspeed_mm.mindspore.mindspore_adaptor
 
 
 def model_provider(pre_process=True, post_process=True):
