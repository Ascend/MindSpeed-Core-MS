training ...
[before the start of training step] datetime: 2025-03-24 18:49:28 
WARNING:megatron.core.models.common.embeddings.rotary_pos_embedding:Setting apply_rope_fusion to false because its implementation is not included in Apex. Try upgrading to the latest version
Number of parameters in transformer layers in billions:  26.19
Number of parameters in embedding layers in billions: 1.85
Total number of parameters in billions: 28.04
Number of parameters in most loaded shard in billions: 14.0214
Number of parameters in other shards in billions: 13.0947
Theoretical memory footprints: weight and optimizer=120346.30 MB
 [2025-03-24 18:49:41] iteration        1/      10 | consumed samples:            8 | elapsed time per iteration (ms): 12445.0 | learning rate: 9.757730E-06 | global batch size:     8 | lm loss: 13.4216022491455078 | loss scale: 1.0 | grad norm: 11.1814639468165140 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:49:44] iteration        2/      10 | consumed samples:           16 | elapsed time per iteration (ms): 3072.9 | learning rate: 9.054634E-06 | global batch size:     8 | lm loss: 13.4041652679443359 | loss scale: 1.0 | grad norm: 10.5262057848251906 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:49:47] iteration        3/      10 | consumed samples:           24 | elapsed time per iteration (ms): 3025.1 | learning rate: 7.959537E-06 | global batch size:     8 | lm loss: 13.5821056365966797 | loss scale: 1.0 | grad norm: 21.6086445958730096 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:49:50] iteration        4/      10 | consumed samples:           32 | elapsed time per iteration (ms): 3031.9 | learning rate: 6.579634E-06 | global batch size:     8 | lm loss: 13.3946361541748047 | loss scale: 1.0 | grad norm: 12.2338184605241302 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:49:53] iteration        5/      10 | consumed samples:           40 | elapsed time per iteration (ms): 3023.8 | learning rate: 5.050000E-06 | global batch size:     8 | lm loss: 13.7305440902709961 | loss scale: 1.0 | grad norm: 12.0741939093964596 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:49:56] iteration        6/      10 | consumed samples:           48 | elapsed time per iteration (ms): 3057.8 | learning rate: 3.520366E-06 | global batch size:     8 | lm loss: 13.5584144592285156 | loss scale: 1.0 | grad norm: 14.8372673414929519 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:49:59] iteration        7/      10 | consumed samples:           56 | elapsed time per iteration (ms): 3043.5 | learning rate: 2.140463E-06 | global batch size:     8 | lm loss: 13.4818792343139648 | loss scale: 1.0 | grad norm: 14.2162152053566846 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:50:02] iteration        8/      10 | consumed samples:           64 | elapsed time per iteration (ms): 3071.5 | learning rate: 1.045366E-06 | global batch size:     8 | lm loss: 13.4469642639160156 | loss scale: 1.0 | grad norm: 13.7689915674380341 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:50:05] iteration        9/      10 | consumed samples:           72 | elapsed time per iteration (ms): 3058.6 | learning rate: 3.422702E-07 | global batch size:     8 | lm loss: 13.3587493896484375 | loss scale: 1.0 | grad norm: 9.8763086200341270 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-24 18:50:08] iteration       10/      10 | consumed samples:           80 | elapsed time per iteration (ms): 3051.5 | learning rate: 1.000000E-07 | global batch size:     8 | lm loss: 13.1875247955322266 | loss scale: 1.0 | grad norm: 11.3457050372736266 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[after training is done] datetime: 2025-03-24 18:50:08 