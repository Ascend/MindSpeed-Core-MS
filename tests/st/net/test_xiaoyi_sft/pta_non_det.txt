 [2025-05-21 14:24:17] iteration        1/      11 | consumed samples:           16 | elapsed time per iteration (ms): 16485.0 | learning rate: 5.000000E-06 | global batch size:    16 | lm loss: 12.0754003524780273 | loss scale: 1.0 | grad norm: 19.7172509544047401 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[Rank 0] (after 1 iterations) memory (MB) | allocated: 11651.56298828125 | max allocated: 12547.5654296875 | reserved: 13350.0 | max reserved: 13350.0
[Rank 1] (after 1 iterations) memory (MB) | allocated: 11651.56298828125 | max allocated: 12547.5654296875 | reserved: 13350.0 | max reserved: 13350.0
[Rank 5] (after 1 iterations) memory (MB) | allocated: 11679.6484375 | max allocated: 12575.65380859375 | reserved: 13090.0 | max reserved: 13090.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 11679.6484375 | max allocated: 12575.65380859375 | reserved: 13090.0 | max reserved: 13090.0
 [2025-05-21 14:24:20] iteration        2/      11 | consumed samples:           32 | elapsed time per iteration (ms): 3086.6 | learning rate: 4.902113E-06 | global batch size:    16 | lm loss: 12.1699361801147461 | loss scale: 1.0 | grad norm: 17.7069252022766079 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:23] iteration        3/      11 | consumed samples:           48 | elapsed time per iteration (ms): 3061.8 | learning rate: 4.618034E-06 | global batch size:    16 | lm loss: 12.0399160385131836 | loss scale: 1.0 | grad norm: 15.4125967822474212 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:26] iteration        4/      11 | consumed samples:           64 | elapsed time per iteration (ms): 3079.8 | learning rate: 4.175571E-06 | global batch size:    16 | lm loss: 11.5355386734008789 | loss scale: 1.0 | grad norm: 15.8696696426245758 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:29] iteration        5/      11 | consumed samples:           80 | elapsed time per iteration (ms): 3063.1 | learning rate: 3.618034E-06 | global batch size:    16 | lm loss: 11.6786975860595703 | loss scale: 1.0 | grad norm: 13.9098119738641461 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:32] iteration        6/      11 | consumed samples:           96 | elapsed time per iteration (ms): 3118.4 | learning rate: 3.000000E-06 | global batch size:    16 | lm loss: 11.1290616989135742 | loss scale: 1.0 | grad norm: 21.3662067195208714 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:35] iteration        7/      11 | consumed samples:          112 | elapsed time per iteration (ms): 3075.9 | learning rate: 2.381966E-06 | global batch size:    16 | lm loss: 11.1138620376586914 | loss scale: 1.0 | grad norm: 15.4319119861084300 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:38] iteration        8/      11 | consumed samples:          128 | elapsed time per iteration (ms): 3091.2 | learning rate: 1.824429E-06 | global batch size:    16 | lm loss: 10.6487312316894531 | loss scale: 1.0 | grad norm: 19.5025222320879799 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:41] iteration        9/      11 | consumed samples:          144 | elapsed time per iteration (ms): 3116.4 | learning rate: 1.381966E-06 | global batch size:    16 | lm loss: 10.8175973892211914 | loss scale: 1.0 | grad norm: 14.7229057649160300 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:45] iteration       10/      11 | consumed samples:          160 | elapsed time per iteration (ms): 3120.6 | learning rate: 1.097887E-06 | global batch size:    16 | lm loss: 10.7655591964721680 | loss scale: 1.0 | grad norm: 11.1536903329989219 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:24:48] iteration       11/      11 | consumed samples:          176 | elapsed time per iteration (ms): 3158.1 | learning rate: 1.000000E-06 | global batch size:    16 | lm loss: 10.6327543258666992 | loss scale: 1.0 | grad norm: 10.7592217790394979 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[after training is done] datetime: 2025-05-21 14:24:48 