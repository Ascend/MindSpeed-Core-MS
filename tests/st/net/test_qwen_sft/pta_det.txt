training ...
[before the start of training step] datetime: 2025-03-20 14:27:32 
 [2025-03-20 14:27:50] iteration        1/      10 | consumed samples:          128 | elapsed time per iteration (ms): 18062.4 | throughput per GPU (TFLOP/s/GPU): 379.4 | learning rate: 1.235606E-06 | global batch size:   128 | lm loss: 9.7951211929321289 | loss scale: 1.0 | grad norm: 20.1497642787274636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:27:54] iteration        2/      10 | consumed samples:          256 | elapsed time per iteration (ms): 4235.8 | throughput per GPU (TFLOP/s/GPU): 1617.9 | learning rate: 1.166872E-06 | global batch size:   128 | lm loss: 9.7579383850097656 | loss scale: 1.0 | grad norm: 23.7711511490950933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:27:58] iteration        3/      10 | consumed samples:          384 | elapsed time per iteration (ms): 4190.8 | throughput per GPU (TFLOP/s/GPU): 1635.3 | learning rate: 1.048292E-06 | global batch size:   128 | lm loss: 9.8505048751831055 | loss scale: 1.0 | grad norm: 36.9996865748971615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:02] iteration        4/      10 | consumed samples:          512 | elapsed time per iteration (ms): 4225.3 | throughput per GPU (TFLOP/s/GPU): 1622.0 | learning rate: 8.921965E-07 | global batch size:   128 | lm loss: 9.6257839202880859 | loss scale: 1.0 | grad norm: 25.7293203331274860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:06] iteration        5/      10 | consumed samples:          640 | elapsed time per iteration (ms): 4079.4 | throughput per GPU (TFLOP/s/GPU): 1680.0 | learning rate: 7.148162E-07 | global batch size:   128 | lm loss: 9.5872354507446289 | loss scale: 1.0 | grad norm: 27.0351616118510805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:10] iteration        6/      10 | consumed samples:          768 | elapsed time per iteration (ms): 4035.8 | throughput per GPU (TFLOP/s/GPU): 1698.1 | learning rate: 5.345956E-07 | global batch size:   128 | lm loss: 9.3978557586669922 | loss scale: 1.0 | grad norm: 24.3384905362274111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:14] iteration        7/      10 | consumed samples:          896 | elapsed time per iteration (ms): 3933.0 | throughput per GPU (TFLOP/s/GPU): 1742.5 | learning rate: 3.702742E-07 | global batch size:   128 | lm loss: 9.3909635543823242 | loss scale: 1.0 | grad norm: 21.0742705195147266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:18] iteration        8/      10 | consumed samples:         1024 | elapsed time per iteration (ms): 4118.1 | throughput per GPU (TFLOP/s/GPU): 1664.2 | learning rate: 2.389384E-07 | global batch size:   128 | lm loss: 9.3132848739624023 | loss scale: 1.0 | grad norm: 26.7052780363732580 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:22] iteration        9/      10 | consumed samples:         1152 | elapsed time per iteration (ms): 4052.1 | throughput per GPU (TFLOP/s/GPU): 1691.3 | learning rate: 1.542448E-07 | global batch size:   128 | lm loss: 9.3942499160766602 | loss scale: 1.0 | grad norm: 22.5240594021842568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-03-20 14:28:26] iteration       10/      10 | consumed samples:         1280 | elapsed time per iteration (ms): 3978.6 | throughput per GPU (TFLOP/s/GPU): 1722.5 | learning rate: 1.250000E-07 | global batch size:   128 | lm loss: 9.4826784133911133 | loss scale: 1.0 | grad norm: 17.7855950864210612 | number of skipped iterations:   0 | number of nan iterations:   0 |
[after training is done] datetime: 2025-03-20 14:28:26 