training ...
[before the start of training step] datetime: 2025-05-21 14:18:53 
WARNING:megatron.core.models.common.embeddings.rotary_pos_embedding:Setting apply_rope_fusion to false because its implementation is not included in Apex. Try upgrading to the latest version
[W compiler_depend.ts:2573] Warning: Tensor not is not allocated by NPUCachingAllocator, skip eraseStream. (function operator())
Number of parameters in transformer layers in billions:  6.53
Number of parameters in embedding layers in billions: 1.09
Total number of parameters in billions: 7.62
Number of parameters in most loaded shard in billions: 1.0882
Number of parameters in other shards in billions: 0.8157
Theoretical memory footprints: weight and optimizer=18680.38 MB
 [2025-05-21 14:19:11] iteration        1/      10 | consumed samples:          128 | elapsed time per iteration (ms): 17909.9 | throughput per GPU (TFLOP/s/GPU): 382.7 | learning rate: 1.235606E-06 | global batch size:   128 | lm loss: 9.7951211929321289 | loss scale: 1.0 | grad norm: 20.1504889719963600 | number of skipped iterations:   0 | number of nan iterations:   0 |
[Rank 2] (after 1 iterations) memory (MB) | allocated: 12480.03173828125 | max allocated: 14014.271484375 | reserved: 13258.0 | max reserved: 14216.0
[Rank 5] (after 1 iterations) memory (MB) | allocated: 12480.07421875 | max allocated: 14014.271484375 | reserved: 13214.0 | max reserved: 14216.0
[Rank 3] (after 1 iterations) memory (MB) | allocated: 12480.03173828125 | max allocated: 14014.271484375 | reserved: 13258.0 | max reserved: 14216.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 12480.07421875 | max allocated: 14014.271484375 | reserved: 13212.0 | max reserved: 14216.0
[Rank 0] (after 1 iterations) memory (MB) | allocated: 16618.2421875 | max allocated: 18688.27587890625 | reserved: 18582.0 | max reserved: 19474.0
[Rank 1] (after 1 iterations) memory (MB) | allocated: 16618.2421875 | max allocated: 18688.27587890625 | reserved: 18582.0 | max reserved: 19474.0
[Rank 6] (after 1 iterations) memory (MB) | allocated: 16630.60888671875 | max allocated: 18692.78662109375 | reserved: 17926.0 | max reserved: 18896.0
[Rank 7] (after 1 iterations) memory (MB) | allocated: 16630.60888671875 | max allocated: 18692.78662109375 | reserved: 17926.0 | max reserved: 18896.0
 [2025-05-21 14:19:16] iteration        2/      10 | consumed samples:          256 | elapsed time per iteration (ms): 4774.8 | throughput per GPU (TFLOP/s/GPU): 1435.3 | learning rate: 1.166872E-06 | global batch size:   128 | lm loss: 9.7579383850097656 | loss scale: 1.0 | grad norm: 23.7712538534597506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:20] iteration        3/      10 | consumed samples:          384 | elapsed time per iteration (ms): 4579.6 | throughput per GPU (TFLOP/s/GPU): 1496.5 | learning rate: 1.048292E-06 | global batch size:   128 | lm loss: 9.8504676818847656 | loss scale: 1.0 | grad norm: 36.9889443866128431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:25] iteration        4/      10 | consumed samples:          512 | elapsed time per iteration (ms): 4656.7 | throughput per GPU (TFLOP/s/GPU): 1471.7 | learning rate: 8.921965E-07 | global batch size:   128 | lm loss: 9.6257724761962891 | loss scale: 1.0 | grad norm: 25.7486003013847089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:29] iteration        5/      10 | consumed samples:          640 | elapsed time per iteration (ms): 4507.2 | throughput per GPU (TFLOP/s/GPU): 1520.5 | learning rate: 7.148162E-07 | global batch size:   128 | lm loss: 9.5870904922485352 | loss scale: 1.0 | grad norm: 27.0243093058274333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:34] iteration        6/      10 | consumed samples:          768 | elapsed time per iteration (ms): 4553.4 | throughput per GPU (TFLOP/s/GPU): 1505.1 | learning rate: 5.345956E-07 | global batch size:   128 | lm loss: 9.3979997634887695 | loss scale: 1.0 | grad norm: 24.3417366184412245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:38] iteration        7/      10 | consumed samples:          896 | elapsed time per iteration (ms): 4508.8 | throughput per GPU (TFLOP/s/GPU): 1520.0 | learning rate: 3.702742E-07 | global batch size:   128 | lm loss: 9.3910436630249023 | loss scale: 1.0 | grad norm: 21.0828480218610572 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:43] iteration        8/      10 | consumed samples:         1024 | elapsed time per iteration (ms): 4511.3 | throughput per GPU (TFLOP/s/GPU): 1519.1 | learning rate: 2.389384E-07 | global batch size:   128 | lm loss: 9.3132324218750000 | loss scale: 1.0 | grad norm: 26.6723830136154128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:47] iteration        9/      10 | consumed samples:         1152 | elapsed time per iteration (ms): 4495.9 | throughput per GPU (TFLOP/s/GPU): 1524.3 | learning rate: 1.542448E-07 | global batch size:   128 | lm loss: 9.3942813873291016 | loss scale: 1.0 | grad norm: 22.5287556319088687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:19:52] iteration       10/      10 | consumed samples:         1280 | elapsed time per iteration (ms): 4483.5 | throughput per GPU (TFLOP/s/GPU): 1528.6 | learning rate: 1.250000E-07 | global batch size:   128 | lm loss: 9.4827508926391602 | loss scale: 1.0 | grad norm: 17.8203998381244233 | number of skipped iterations:   0 | number of nan iterations:   0 |
[after training is done] datetime: 2025-05-21 14:19:52 
