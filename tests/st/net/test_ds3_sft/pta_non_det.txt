 [2025-05-21 14:14:39] iteration        1/      10 | consumed samples:            8 | elapsed time per iteration (ms): 17388.6 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.5055196285247803 | loss scale: 1.0 | grad norm: 30.5078306307964660 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[Rank 0] (after 1 iterations) memory (MB) | allocated: 16805.6318359375 | max allocated: 17467.81298828125 | reserved: 18310.0 | max reserved: 18310.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 16640.2607421875 | max allocated: 17088.26318359375 | reserved: 17432.0 | max reserved: 17432.0
 [2025-05-21 14:14:39] iteration        2/      10 | consumed samples:           16 | elapsed time per iteration (ms): 576.3 | learning rate: 9.701478E-06 | global batch size:     8 | lm loss: 4.0182037353515625 | loss scale: 1.0 | grad norm: 24.5773605935942321 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:40] iteration        3/      10 | consumed samples:           24 | elapsed time per iteration (ms): 506.0 | learning rate: 8.841920E-06 | global batch size:     8 | lm loss: 6.6553277969360352 | loss scale: 1.0 | grad norm: 26.3783260616633832 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:40] iteration        4/      10 | consumed samples:           32 | elapsed time per iteration (ms): 513.8 | learning rate: 7.525000E-06 | global batch size:     8 | lm loss: 7.3994584083557129 | loss scale: 1.0 | grad norm: 29.8324946884116002 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:41] iteration        5/      10 | consumed samples:           40 | elapsed time per iteration (ms): 514.8 | learning rate: 5.909558E-06 | global batch size:     8 | lm loss: 7.8787059783935547 | loss scale: 1.0 | grad norm: 45.1551120707076095 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:41] iteration        6/      10 | consumed samples:           48 | elapsed time per iteration (ms): 518.6 | learning rate: 4.190442E-06 | global batch size:     8 | lm loss: 7.0007390975952148 | loss scale: 1.0 | grad norm: 65.0190342543524054 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:42] iteration        7/      10 | consumed samples:           56 | elapsed time per iteration (ms): 494.9 | learning rate: 2.575000E-06 | global batch size:     8 | lm loss: 8.9156417846679688 | loss scale: 1.0 | grad norm: 67.4179611679047355 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:42] iteration        8/      10 | consumed samples:           64 | elapsed time per iteration (ms): 502.0 | learning rate: 1.258080E-06 | global batch size:     8 | lm loss: 8.3894538879394531 | loss scale: 1.0 | grad norm: 112.8329331932316677 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:43] iteration        9/      10 | consumed samples:           72 | elapsed time per iteration (ms): 502.1 | learning rate: 3.985215E-07 | global batch size:     8 | lm loss: 10.7227420806884766 | loss scale: 1.0 | grad norm: 39.1689933139906685 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-21 14:14:43] iteration       10/      10 | consumed samples:           80 | elapsed time per iteration (ms): 506.4 | learning rate: 1.000000E-07 | global batch size:     8 | lm loss: 10.0526390075683594 | loss scale: 1.0 | grad norm: 68.0683604678219467 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[after training is done] datetime: 2025-05-21 14:14:43 