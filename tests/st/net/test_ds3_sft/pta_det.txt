 [2025-05-06 16:15:06] iteration        1/      10 | consumed samples:            8 | elapsed time per iteration (ms): 17382.0 | learning rate: 1.000000E-05 | global batch size:     8 | lm loss: 2.5055196285247803 | loss scale: 1.0 | grad norm: 30.5073025200452719 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[Rank 0] (after 1 iterations) memory (MB) | allocated: 16805.6318359375 | max allocated: 17467.81298828125 | reserved: 18310.0 | max reserved: 18310.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 16640.2607421875 | max allocated: 17088.26318359375 | reserved: 17432.0 | max reserved: 17432.0
 [2025-05-06 16:15:06] iteration        2/      10 | consumed samples:           16 | elapsed time per iteration (ms): 821.2 | learning rate: 9.701478E-06 | global batch size:     8 | lm loss: 4.0182037353515625 | loss scale: 1.0 | grad norm: 24.5777919235020157 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:07] iteration        3/      10 | consumed samples:           24 | elapsed time per iteration (ms): 746.4 | learning rate: 8.841920E-06 | global batch size:     8 | lm loss: 6.6559705734252930 | loss scale: 1.0 | grad norm: 26.3775372482527040 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:08] iteration        4/      10 | consumed samples:           32 | elapsed time per iteration (ms): 737.1 | learning rate: 7.525000E-06 | global batch size:     8 | lm loss: 7.3979940414428711 | loss scale: 1.0 | grad norm: 29.8245666203823987 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:09] iteration        5/      10 | consumed samples:           40 | elapsed time per iteration (ms): 727.2 | learning rate: 5.909558E-06 | global batch size:     8 | lm loss: 7.8820257186889648 | loss scale: 1.0 | grad norm: 45.1581563685773872 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:09] iteration        6/      10 | consumed samples:           48 | elapsed time per iteration (ms): 719.7 | learning rate: 4.190442E-06 | global batch size:     8 | lm loss: 6.9983172416687012 | loss scale: 1.0 | grad norm: 64.9748680239632819 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:10] iteration        7/      10 | consumed samples:           56 | elapsed time per iteration (ms): 684.7 | learning rate: 2.575000E-06 | global batch size:     8 | lm loss: 8.9150371551513672 | loss scale: 1.0 | grad norm: 67.4178867048938741 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:11] iteration        8/      10 | consumed samples:           64 | elapsed time per iteration (ms): 699.5 | learning rate: 1.258080E-06 | global batch size:     8 | lm loss: 8.3893833160400391 | loss scale: 1.0 | grad norm: 113.2351324499038441 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:11] iteration        9/      10 | consumed samples:           72 | elapsed time per iteration (ms): 728.4 | learning rate: 3.985215E-07 | global batch size:     8 | lm loss: 10.7215175628662109 | loss scale: 1.0 | grad norm: 39.1557762318268274 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-05-06 16:15:12] iteration       10/      10 | consumed samples:           80 | elapsed time per iteration (ms): 705.4 | learning rate: 1.000000E-07 | global batch size:     8 | lm loss: 10.0541715621948242 | loss scale: 1.0 | grad norm: 68.1348817150455091 | num zeros: 0.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
[after training is done] datetime: 2025-05-06 16:15:12
